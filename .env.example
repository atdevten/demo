# Server Configuration
PORT=3000
NODE_ENV=production

# Qdrant Configuration
# URL for Qdrant service (use service name in Docker: qdrant)
QDRANT_URL=http://qdrant:6333
# Optional: Qdrant API key if you're using Qdrant Cloud
QDRANT_API_KEY=

# Collection Configuration
# Name of the collection in Qdrant where documents will be stored
COLLECTION_NAME=documents

# Ollama Configuration
# URL for Ollama service (use service name in Docker: ollama)
OLLAMA_URL=http://ollama:11434

# Embedding Model
# Model used for creating embeddings (vector representations of text)
# Options: nomic-embed-text (768 dims), all-minilm (384 dims)
# Default: nomic-embed-text
EMBEDDING_MODEL=nomic-embed-text

# LLM Model
# Model used for generating answers
# Options: mistral, llama2, codellama, etc.
# Default: mistral
LLM_MODEL=mistral

# Document Processing Configuration
# Chunk size: Number of characters per chunk (default: 1000)
CHUNK_SIZE=1000
# Chunk overlap: Number of characters to overlap between chunks (default: 200)
CHUNK_OVERLAP=200
